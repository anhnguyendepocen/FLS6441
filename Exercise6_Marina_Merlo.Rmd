---
title: "Replication 6 - Difference-in-Differences"
author: "Marina Merlo"
date: "22 de maio de 2019"
output: pdf_document

---

```{r, echo=FALSE, warning=F, message=F}
library(tidyverse)
library(ggplot2)
library(knitr)
library(data.table)
library(effects)
library(MASS)
library(Zelig)
library(ZeligChoice)
library(estimatr)
library(stargazer)
library(float)
library(pander)
library(texreg)
library(plm)
library(RCurl)
library(gdata) 
library(zoo)
library(gridExtra)
 
knitr::opts_chunk$set(echo = FALSE)
data <- fread("https://jonnyphillips.github.io/Methods_III/Classes/Class_8/Replication/Vietnam0810.csv")
```

## 1. What is treatment and control in this study? What is the treatment assignment mechanism?

The treatment is to have their District People's Council (DCP) abolished after 2009, the control is to still have it. The treatment assignment mechanism was designed by the Ministry Of Home Affairs through a stratified sample by region, sub-region and other characteristics.

## 2. Run the ‘naive’ cross-sectional OLS regression of the infrastructure index (one of the 6 presented in Table 3 of Malesky et al) on treatment.  How do you interpret the results? Provide at least one specific reason why the treatment effect in your regression may be a biased estimate.

The results show there's no significant impact of the treatment on the infrastructure index. However, this is a biased estimate because we're comparing treated units across time, even when they weren't treated yet. 

```{r,echo=FALSE, warning=F, message=F,results='asis'}
data %>%
  lm(index_infra ~ treatment,
                     data = .)%>%
  stargazer(header=F,no.space = T,font.size = "small")

```

## 3. Run the ‘naive’ before-after OLS regression of the infrastructure index on the time variable(1 for 2010, 0 for 2008) for the treated units only. How do you interpret the results? Provide at least one specific reason why the treatment effect in your regression may be a biased estimate.

There's a positive and significant effect of 0.49 on the infrastructure index after the removal of the district council. This might be biased due other temporal changes and not only the treatment, such as an improvment on economy etc. 

```{r,echo=FALSE, warning=F, message=F,results='asis'}
data %>%
  filter(treatment == 1) %>%
  lm(index_infra ~ time,
                     data = .)%>%
  stargazer(header=F,no.space = T,font.size = "small")

```

## 4. Now perform the main Difference-in-differences analysis for the Infrastructure Index out-come. Don’t cluster your standard errors or include any control variables yet. Interpret the results.

Our average treatment effect is the coefficient of the interaction term between time and treatment. This coefficient is positive and significant at 5% level, showing there's an increase of 0.25 of the infrastructure index after the removal of district councils on treated communes. 

```{r,echo=FALSE, warning=F, message=F,results='asis'}
data %>%
  lm(index_infra ~ time + treatment + time*treatment,
                     data = .)%>%
  stargazer(header=F,no.space = T,font.size = "small")

```

## 5. Repeat Q4 but now add the control variables (lnarea,lnpopden,city, and Region fixed effects)used in Table 3 of Malesky et al. Compare your answers to those in Table 3.

There're small differences from the results in Table 3 in the paper and the ones below, but the interpretation remains the same. Our ATE is 0.227 and in Malesky et al., 0.225, both significant at 5% level. 

```{r,echo=FALSE, warning=F, message=F,results='asis'}
data %>%
  lm(index_infra ~ time + treatment + time*treatment + lnarea + lnpopden + city + Region,
                     data = .)%>%
  stargazer(header=F,no.space = T,font.size = "small")

```

## 6. Repeat Q5 but now with clustered standard errors at the District level. How does this alter your results?

There's an incrase in our standard errors and our ATE now is significant at 10%. 

```{r,echo=FALSE, warning=F, message=F,results='asis'}

#removing the 3 rows with NA in lnpopden that causes error in the clustered SEs estimation in stargazer
data2 <- data %>%
  filter(!is.na(lnpopden))

reg1 <- data2 %>%
  lm(index_infra ~ time + treatment + time*treatment + lnarea + lnpopden + city + Region,
                     data = .)

stargazer(reg1,se=starprep(reg1,clusters = data2$District), header=F,no.space = T,font.size = "small")

```

## 7. Replicate all of the columns of Table 3 of Malesky et al.

```{r,echo=FALSE, warning=F, message=F,results='asis'}

reg2 <- data2 %>%
  lm(index_agric ~ time + treatment + time*treatment + lnarea + lnpopden + city + Region,
                     data = .)
reg3 <- data2 %>%
  lm(index_health ~ time + treatment + time*treatment + lnarea + lnpopden + city + Region,
                     data = .)
reg4 <- data2 %>%
  lm(index_education ~ time + treatment + time*treatment + lnarea + lnpopden + city + Region,
                     data = .)
reg5 <- data2 %>%
  lm(index_comms ~ time + treatment + time*treatment + lnarea + lnpopden + city + Region,
                     data = .)
reg6 <- data2 %>%
  lm(index_bus_dev ~ time + treatment + time*treatment + lnarea + lnpopden + city + Region,
                     data = .)

stargazer(reg1,reg2,reg3,reg4,reg5,reg6,se=starprep(reg1,reg2,reg3,reg4,reg5,reg6,clusters = data2$District), header=F,no.space = T,column.sep.width = "2pt",font.size = "scriptsize")

```

(see Table 6 below)

## 8. Assess the balance in land area (totalland) of the treated and control units in timet= 0.Focus on the substantive difference, not the p-value. Is there are any evidence of imbalance? Would this create a risk of bias for our difference-in-differences analysis?

```{r,echo=FALSE, warning=F, message=F,results='asis'}


```

## 9. Difference-in-differences methodology cannot protect us against time-varying confounders.Provide an example of an omitted (confounding) variable that might create bias in our results.

## 10. One way of testing for the presence of time-varying confounders is to check that there are parallel pre-treatment trendsin the outcomes for treated and control units. Using the second dataset,Vietnam0608.csv, and your main difference-in-differences regression, assess if treated units had a different trend to control units before treatment, i.e. between 2006 and 2008, foreach of the 6 outcome indices. This should replicate Panel 2 of Table 3 in Malesky et al.

## 11. Create a Difference-in-differences chart showing the average Infrastructure Index outcomeby treatment group between 2008 and 2010. Compare this to the same chart between 2006and 2008.  What do these charts suggest about the validity of our difference-in-differences methodology?