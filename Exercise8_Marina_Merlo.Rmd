---
title: "Replication 8 - Matching"
author: "Marina Merlo"
date: "5 de junho de 2019"
output: pdf_document
---

```{r, echo=FALSE, warning=F, message=F}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(knitr)
library(data.table)
library(effects)
library(MASS)
library(Zelig)
library(ZeligChoice)
library(estimatr)
library(stargazer)
library(float)
library(pander)
library(texreg)
library(plm)
library(RCurl)
library(gdata) 
library(zoo)
library(gridExtra)
#install.packages("MatchIt")
library(MatchIt)
#install.packages("optmatch")
library(optmatch)
#install.packages("rgenoud")
library(rgenoud)
#install.packages("combinat")
#install.packages("cem",repos="http://r.iq.harvard.edu", type="source") 
library(cem)

data <- fread("https://jonnyphillips.github.io/Methods_III/Classes/Class_10/Replication/Boas_Hidalgo.csv")
```

## 1. What is treatment? What is control? What is the outcome?

The treatment is controling a community radio, the control is to own none. The outcome is the vote share in the next election and the probability of winning. 

## 2. Why do Boas and Hidalgo not use an experiment or natural experiment to estimate the effect of possessing a radio licence?

Because the treatment, the radio license, isn't randomly assigned. The treatment is very likely to be part of the incumbent advantage, so their potential outcomes (winning and vote share) are already higher.

## 3.  Conduct and interpret a basic linear regression of the outcome on treatment with no controls.

In this regression, we can say that owning an radio station increases the vote share in 0.45% in the next election. 

```{r,echo=FALSE, warning=F, message=F,results='asis'}
data %>%
  lm(pctVV ~ treat,
                     data = .)%>%
  stargazer(header=F,no.space = T,font.size = "small")

```


## 4. One potential confounding variable is gender (this could affect the chances of an application being approved if there is bias in the Ministry, and the candidate’s vote share if there is bias among voters). Is there balance across control and treatment groups on the male variable? 

There are more males in the treated group - this difference is statistically significant at 5% level. This means our results in the basic linear regression is biased.

```{r,echo=FALSE, warning=F, message=F}
data %>%
  t.test(treat~male,data=.)

```

## 5. One way of controlling for gender is to add it as a control variable to your regression in Q3.Interpret the result. 

When adding the gender variable, the treatment effect is slightly reduced, but there still might be bias in other variables. 


```{r,echo=FALSE, warning=F, message=F,results='asis'}
data %>%
  lm(pctVV ~ treat + male,
                     data = .)%>%
  stargazer(header=F,no.space = T,font.size = "small")

```

##6. An alternative approach is to use matching. Let’s try to do one-to-one exact matching on gender manually. There are 311 treated units but 1144 control units in your data, so one-to-one matching means throwing away 833 control units.
*(a) Split your data into four differents datasets: treated males, treated females, control males and control females;*

```{r,echo=TRUE, warning=F, message=F}
t_male <- data %>%
  filter(treat == 1 & male == 1)
c_male <- data %>%
  filter(treat == 0 & male == 1)
t_female <- data %>%
  filter(treat == 1 & male == 0)
c_female <- data %>%
  filter(treat == 0 & male == 0)

```

*(b) How many treated males do you have? Reduce your dataset of control males so you have only the same number as the number of treated males - since they are exactly matched on gender it doesn’t matter which you pick so choose which ones to keep/drop randomly;*

```{r,echo=TRUE, warning=F, message=F}

c_male <- c_male %>%
  sample_n(size = nrow(t_male))

```
*(c) Do the same for control females - reduce the number of control females to the same as the number of treated females;*

```{r,echo=TRUE, warning=F, message=F}

c_female <- c_female %>%
  sample_n(size = nrow(t_female))

```
*(d) Join your four datasets back together to make one dataset (this will be smaller than the original datasetas we threw some data away);*

```{r,echo=TRUE, warning=F, message=F}

datamatch <- rbind(c_female,t_female,c_male,t_male)

```
*(e) Check for balance in gender on the new dataset - it should be perfectly balanced, right?*

```{r,echo=FALSE, warning=F, message=F}
datamatch %>%
  t.test(treat~male,data=.)

```

##7. Using the matched dataset from Q6, conduct two analyses of the difference in outcomes between treated and control groups. One using a difference-in-means t-test and one using a simple linear regression. Interpret the results.

The t-test shows a difference between treated and control groups in the outcome variable significant at 5% level. The regressions tells the same story, with a positive and significant effect of 0.405% in the vote share for the candidates controlling a radio community - this coefficient, however, is smaller than the one estimated with the full data, meaning that some of the previous effect was due to inbalance on gender.

```{r,echo=FALSE, warning=F, message=F}
datamatch %>%
  t.test(pctVV~treat,data=.)

```
```{r,echo=FALSE, warning=F, message=F,results='asis'}
datamatch %>%
  lm(pctVV ~ treat,
                     data = .)%>%
  stargazer(header=F,no.space = T,font.size = "small")


```



##8. To match on continuous or multiple variables it’s easier to use matchit. Return to your original full dataset and, using nearest neighbour matching, match on the size of the electorate (log.valid.votes). How many units are matched? Why this number? Conduct a simple balance t-test on the size of the electorate for the full dataset and for your matched dataset (you can recover it withmatch.data(output_of_matchit)). How does balance change after matching? 

The matching using nearest neighbour method got us 622 units matched, removing 833 that couldn't be matched. This number was limited to our treated units in the full dataset - each treated variable is matched to a single control unit.
The t.test for the full dataset shows we had an imbalance in the total votes variable significant at 5% level. The same test with the trimmed data now shows treated and control groups are balanced. 

```{r,echo=FALSE, warning=F, message=F}

match1 <- matchit(treat ~ log.valid.votes, data = data, method = "nearest")
summary(match1)

datamatchit1 <- match.data(match1)

data %>%
t.test(log.valid.votes~treat,data=.)

datamatchit1 %>%
t.test(log.valid.votes~treat,data=.)

```

## 9. Let’s see which units were dropped by our matching method in Q8. For the full (unmatched)dataset, create a graph of the size of the electorate against the outcome variable. Colour thepoints according to treatment status. Make this layer semi-transparent if you can. Finally,add another layer to your graph showing the same variables for thematcheddata. What does this graph tell you about which units were matched?

## 10. Using the matched dataset from Q8, conduct two analyses of the difference in outcomesbetween treated and control groups. One using a difference-in-means t-test and one using asimple linear regression. Interpret the results.

## 11. Now let’s include all of the matching variables that Boas and Hidalgo use, and use nearestneighbour matching inmatchitto construct a matched dataset.  Use the list of matchingvariables provided below to conduct nearest neighbour matching.“occBlue.collar”, “occEducation”, “occGovernment”, “occMedia”, “occNone”, “occOther”, “occPolitician”, “oc-cWhite.collar”, “lat”, “long”, “ran.prior”, “incumbent”, “log.valid.votes”, “party.prior.pctVV”, “prior.pctVV”,“elec.year”,   “match.partyPCB”,   “match.partyPC.do.B”,   “match.partyPDT”,   “match.partyPFL”,“match.partyPL”,  “match.partyPMDB”,  “match.partyPMN”,  “match.partyPP”,  “match.partyPPS”,“match.partyPSB”, “match.partyPSC”, “match.partyPSDB”, “match.partyPSDC”, “match.partyPSL”,“match.partyPT”, “match.partyPTB”, “match.partyPV”, “uf.rs”, “uf.sp”, “yob”, “eduMore.than.Primary..Less.than.Superior”,“eduSome.Superior.or.More”, “log.total.assets”, “pt_pres_1998”, “psdb_2000”, “hdi_2000”, “income_2000”,“log.num.apps”

## 12. Using your matched dataset from Q11, conduct a simple linear regression of the outcomeon treatment. Interpret the results and compare them to the result in the first column ofTable 4 in Boas and Hidalgo (2011) (it probably won’t be the same, see the next questions).

## 13. With lots of variables it’s impossible to get perfect balance on all variables, there are justtoo many dimensions and too few units. One option to control for ‘residual confounding’ is toinclude the matching variables as control variables in our analysis regression. How does thischange your estimated treatment effect?

## 14. One risk with nearest-neighbour matching is that the control unit can still be far awayfrom the treated unit if there are no good matches. Re-run the matching process from Q11but with a caliper of 0.01 standard deviations, and then re-run the regression from Q12 (nocontrols). How does the number of units and the result change?

## 15. Another problem with nearest neighbour matching is that it is ‘greedy’ - the first matchesmight make it harder to match well later. Boas and Hidalgo use genetic matching, which isa complex automated process to try and get the best ‘overall’ matches for the full dataset.Run genetic matching with the same variables and then run your regression (with no controls)again. Note:Genetic matching might take 10-20 minutes.